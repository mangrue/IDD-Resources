{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mangrue/IDD-Resources/blob/main/IDD_CrossModelsDatasets_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeaYDCuSzZdv"
      },
      "source": [
        "#**Setting up environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9dasqVDUSwcF"
      },
      "outputs": [],
      "source": [
        "#Install specific libraries\n",
        "#! pip install torch\n",
        "#! pip install transformers\n",
        "#! pip install pycaret\n",
        "#! pip install pandas\n",
        "#! pip install numpy\n",
        "#! pip install pycaret\n",
        "#! pip install matplotlib\n",
        "#! pip install -U scikit-learn\n",
        "#! pip install transformers==2.8.0\n",
        "#!pip install --upgrade huggingface_hub\n",
        "!pip install evaluate -q\n",
        "!pip install datasets -q\n",
        "!pip install -U datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import pycaret\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Set Working Directory - if working on Google Drive\n",
        "# Mount Google Drive - applicable, if working on Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#%cd /content/drive/MyDrive #/Colab_Notebooks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r6TBcGAw6TH"
      },
      "source": [
        "#**Hugging Face**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2v-BhRzd4ndZ"
      },
      "outputs": [],
      "source": [
        "#login to hugging face\n",
        "!huggingface-cli login --token #hugging face token #--add-to-git-credential\n",
        "\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8FEd4rZxBEk"
      },
      "source": [
        "#**Load dataset(s)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdpHvnzzDrIe"
      },
      "outputs": [],
      "source": [
        "#Check dataset(s)\n",
        "\n",
        "#!pip install -U datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "#Load and check data\n",
        "dataset = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/LIAR_final.csv\", token=True)\n",
        "#dataset = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/ISOT_final.csv\", token=True)   #use_auth_token deprecated since v5 of Transformers, Sept. 2024 (use \"token\" instead)\n",
        "#dataset = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/BuzzFeed-2016_final.csv\", token=True)\n",
        "#dataset = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/NELA-GT-2018_final.csv\", token=True)\n",
        "#app. 20% of NELA-GT-2018 dataset loaded\n",
        "#dataset = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/NELA-GT-2022_final.csv\", token=True)\n",
        "#app. 10% of NELA-GT-2022 dataset loaded\n",
        "\n",
        "#dataset = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/WELFake_final.csv\", token=True)\n",
        "\n",
        "print('Dataset info:')\n",
        "print('Size: ' + str(len(dataset)))\n",
        "\n",
        "dataset\n",
        "\n",
        "dataset.set_format(type='pandas')\n",
        "df = dataset['train'][:]\n",
        "print(df)\n",
        "\n",
        "df.sample(n=10)\n",
        "\n",
        "#Check if None values exist in rows and then check for duplicates\n",
        "#null_mask = df.isnull().any(axis=1)\n",
        "#null_rows = df[null_mask]\n",
        "#print(f\"Null rows: {null_rows}\")\n",
        "\n",
        "#item0 = df.shape[0]\n",
        "#df = df.drop_duplicates()\n",
        "#item1 = df.shape[0]\n",
        "#print(f\"Duplicates found: {item0-item1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eRq5eSzDuAf"
      },
      "source": [
        "**Load dataset(s) and libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-P9SB5mcDzEF"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from evaluate import evaluator\n",
        "import evaluate\n",
        "from transformers import AutoModelForSequenceClassification, pipeline\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/LIAR_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                                    #LIAR\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/ISOT_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                                   #ISOT (title+text)\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/ISOT_final_only_title.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                        #ISOT (only title)\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/ISOT_final_only_text.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                         #ISOT (only text, title not merged)\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/BuzzFeed-2016_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                          #BuzzFeed (merged title + text, like all other datasets)\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/BuzzFeed-2016_final_titles_sentence_case.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))     #BuzzFeed (final sentence cased)   #FINAL ONE USED FOR EVALUATION\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/BuzzFeed-2016_final_only_text.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                #BuzzFeed (only text)\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS//NELA-GT-2018_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                          #NELA-GT-2018\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS//NELA-GT-2022_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                          #NELA-GT-2022\n",
        "\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/WELFake_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))                    #WELFake\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/clmentbisaillon_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))            #ISOT\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/jy46604790_fake_dataset_EU_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500)) #EU news / EUvsDisinfo\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/COVID19-fake-news_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))          #COVID-19 content\n",
        "\n",
        "#EU mixed data\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_1_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_2_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_3_EMNAD_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_4_enr_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_5_enr_Belgium_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_6_enr_Belgium_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#Each MS/country\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_Belgium_EUvsDis_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_Cyprus_EUvsDis_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_Ireland_EUvsDis_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_Malta_EUvsDis_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "#eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/EU_mix_United_Kingdom_EUvsDis_final.csv\", token=True, split=\"train\").shuffle(seed=42).select(range(500))\n",
        "\n",
        "#print(eval_data)\n",
        "\n",
        "#df = pd.DataFrame(eval_data)\n",
        "#df = df[[\"text\", \"label\"]]\n",
        "\n",
        "#df = df.sample(frac=1, random_state=42).reset_index(drop=True).head(100)  #limit by head or sample size of data sample\n",
        "#print(df)\n",
        "#display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1WjM0G2rH5j"
      },
      "source": [
        "#**Evaluation of model's performance on certain dataset(s)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh-KxloSZq91"
      },
      "source": [
        "**1) MODEL: dima806/fake-news-classifier (pre-trained on: WELFake)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YzEA8DaXDczm"
      },
      "outputs": [],
      "source": [
        "#example\n",
        "\n",
        "MODEL = \"dima806/fake-news-classifier\"\n",
        "clf = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL)\n",
        "\n",
        "#Small samples' classification\n",
        "\n",
        "# testing on unseen data #example from below from LIAR trained model example\n",
        "#unseen_news_text = [\"Donald Trump Sends Out Embarrassing New Yearâ€™s Eve Message; This is Disturbing\",     # Fake\n",
        "#                    \"WATCH: George W. Bush Calls Out Trump For Supporting White Supremacy\",               # Fake\n",
        "#                    \"U.S. lawmakers question businessman at 2016 Trump Tower meeting: sources\",           # True\n",
        "#                    \"Trump administration issues new rules on U.S. visa waivers\"                          # True\n",
        "#                    ]\n",
        "\n",
        "# random examples from LIAR dataset\n",
        "\n",
        "df = pd.DataFrame(eval_data)\n",
        "sampledf = df.sample(n=10)\n",
        "sample = sampledf[[\"text\", \"label\"]]\n",
        "print(sample)\n",
        "data = sampledf[\"text\"]\n",
        "data = data.values.tolist()\n",
        "print(data)\n",
        "\n",
        "i = 0\n",
        "while i < len(data):\n",
        "    text = data[i]\n",
        "    result = clf(text[:512])\n",
        "    print(result)\n",
        "    i += 1\n",
        "\n",
        "# make a classification pipeline\n",
        "#sample_title = '''Elon Musk buys Twitter'''\n",
        "#pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL)\n",
        "#sample_title = '''Elon Musk buys Twitter'''\n",
        "#pipe(sample_title, top_k=None)\n",
        "# output of trained model matches claimed output for this example\n",
        "\n",
        "#from transformers import pipeline\n",
        "#MODEL = \"jy46604790/Fake-News-Bert-Detect\"\n",
        "#clf = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL)\n",
        "\n",
        "#text = \"Indonesian police have recaptured a U.S. citizen who escaped a week ago from an overcrowded prison on the holiday island of Bali, the jail s second breakout of foreign inmates this year.  Cristian Beasley from California was rearrested on Sunday, Badung Police chief Yudith Satria Hananta said, without providing further details.  Beasley was a suspect in crimes related to narcotics but had not been sentenced when he escaped from Kerobokan prison in Bali last week. The 32-year-old is believed to have cut through bars in the ceiling of his cell before scaling a perimeter wall of the prison in an area being refurbished. The Kerobokan prison, about 10 km (six miles) from the main tourist beaches in the Kuta area, often holds foreigners facing drug-related charges. Representatives of Beasley could not immediately be reached for comment. In June, an Australian, a Bulgarian, an Indian and a Malaysian tunneled to freedom about 12 meters (13 yards) under Kerobokan prison s walls. The Indian and the Bulgarian were caught soon after in neighboring East Timor, but Australian Shaun Edward Davidson and Malaysian Tee Kok King remain at large. Davidson has taunted authorities by saying he was enjoying life in various parts of the world, in purported posts on Facebook.  Kerobokan has housed a number of well-known foreign drug convicts, including Australian Schappelle Corby, whose 12-1/2-year sentence for marijuana smuggling got huge media attention.\"\n",
        "\n",
        "#result = clf(text)\n",
        "#result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC-Ty7da3zwc"
      },
      "outputs": [],
      "source": [
        "#EVALUATE model's performance on the data\n",
        "\n",
        "MODEL = \"dima806/fake-news-classifier\"\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "# 1. Pass a model name or path\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(MODEL, max_len=512),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"REAL\": 1}\n",
        ")\n",
        "\n",
        "# 2. Pass an instantiated model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(MODEL, max_len=512),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"REAL\": 1}\n",
        ")\n",
        "\n",
        "# 3. Pass an instantiated pipeline\n",
        "pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(MODEL, max_len=512))\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    label_mapping={\"FAKE\": 0, \"REAL\": 1},\n",
        "    strategy=\"bootstrap\", #calculate confidence intervals using the boostrap method\n",
        "    n_resamples=200 #use 200 for n_resamples (default is 9999), default for confidence_level is 0.95\n",
        ")\n",
        "print(\"___________\")\n",
        "print(\"dima806\")\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(\"___________\")\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7JeCmjvVUZw"
      },
      "source": [
        "**2) MODEL: hamzab/roberta-fake-news-classification (pre-trained on: ISOT)**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmpS-M-ZVTMK"
      },
      "outputs": [],
      "source": [
        "#FORMAT input: <title> TITLE HERE <content> CONTENT HERE <end>\n",
        "\n",
        "MODEL = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\") #, config=AutoConfig.from_pretrained(\"hamzab/roberta-fake-news-classification\"))\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "#import torch\n",
        "#def predict_fake(title,text):\n",
        "#    input_str = \"<title>\" + title + \"<content>\" +  text + \"<end>\"\n",
        "#    input_ids = tokenizer.encode_plus(input_str, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "#    device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#    model.to(device)\n",
        "#    with torch.no_grad():\n",
        "#        output = model(input_ids[\"input_ids\"].to(device), attention_mask=input_ids[\"attention_mask\"].to(device))\n",
        "#    return dict(zip([\"Fake\",\"Real\"], [x.item() for x in list(torch.nn.Softmax()(output.logits)[0])] ))#\n",
        "\n",
        "#print(predict_fake(<HEADLINE-HERE>,<CONTENT-HERE>))\n",
        "\n",
        "#import gradio as gr\n",
        "#iface = gr.Interface(fn=predict_fake, inputs=[gr.inputs.Textbox(lines=1,label=\"headline\"),gr.inputs.Textbox(lines=6,label=\"content\")], outputs=\"label\").launch(share=True)\n",
        "\n",
        "# 1. Pass a model name or path\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        ")\n",
        "\n",
        "# 2. Pass an instantiated model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        ")\n",
        "\n",
        "# 3. Pass an instantiated pipeline\n",
        "pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\"))\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1},\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "print(\"___________\")\n",
        "print(\"hamzab\")\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(\"___________\")\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-cI76XujWpk"
      },
      "source": [
        "**-) Special evaluation regarding text with and without title**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SLcWPwYpjfwL"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from evaluate import evaluator\n",
        "import evaluate\n",
        "from transformers import AutoModelForSequenceClassification, pipeline\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "seed_count = 42\n",
        "\n",
        "while seed_count < 52:\n",
        "\n",
        "  #eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/BuzzFeed-2016_final_only_text.csv\", use_auth_token=True, split=\"train\").shuffle(seed=seed_count).select(range(500))     #BuzzFeed (only text)\n",
        "  #eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/BuzzFeed-2016_final.csv\", use_auth_token=True, split=\"train\").shuffle(seed=seed_count).select(range(500))     #BuzzFeed (merged title + text, like all other datasets)\n",
        "  eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/BuzzFeed-2016_final_titles_sentence_case.csv\", token=True, split=\"train\").shuffle(seed=seed_count).select(range(500))     #BuzzFeed (final sentence cased)\n",
        "\n",
        "  #Store samples for closer inspection\n",
        "  #df = pd.DataFrame(eval_data)\n",
        "  #df = df[[\"text\", \"label\"]]\n",
        "  #df.to_csv(\"/content/drive/MyDrive/Colab_Notebooks/data_samples_hamzab_on_BuzzFeed_special_evaluation/sample_seed_\" + str(seed_count) + \".csv\", sep=',', index=False, encoding='utf-8')\n",
        "\n",
        "  #FORMAT input: <title> TITLE HERE <content> CONTENT HERE <end>\n",
        "\n",
        "  MODEL = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
        "  task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\") #, config=AutoConfig.from_pretrained(\"hamzab/roberta-fake-news-classification\"))\n",
        "\n",
        "  # 1. Pass a model name or path\n",
        "  eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        "  )\n",
        "\n",
        "  # 2. Pass an instantiated model\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\"hamzab/roberta-fake-news-classification\")\n",
        "\n",
        "  eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        "  )\n",
        "\n",
        "  # 3. Pass an instantiated pipeline\n",
        "  pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"hamzab/roberta-fake-news-classification\"))\n",
        "\n",
        "  eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1},\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        "  )\n",
        "  print(\"___________\")\n",
        "  print(\"hamzab\")\n",
        "  print(\"EVALUATION RESULTS (SEED:\" + str(seed_count) + \"):\")\n",
        "  print(\"___________\")\n",
        "  print(eval_results)\n",
        "  seed_count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTFcp2w6_T2M"
      },
      "source": [
        "**3) MODEL: jy46604790/Fake-News-Bert-Detect (pre-trained on ISOT)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j72zqMBe_TPE"
      },
      "outputs": [],
      "source": [
        "MODEL = \"jy46604790/Fake-News-Bert-Detect\"\n",
        "#clf = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL)\n",
        "\n",
        "#text = \"Indonesian police have recaptured a U.S. citizen who escaped a week ago from an overcrowded prison on the holiday island of Bali, the jail s second breakout of foreign inmates this year.  Cristian Beasley from California was rearrested on Sunday, Badung Police chief Yudith Satria Hananta said, without providing further details.  Beasley was a suspect in crimes related to narcotics but had not been sentenced when he escaped from Kerobokan prison in Bali last week. The 32-year-old is believed to have cut through bars in the ceiling of his cell before scaling a perimeter wall of the prison in an area being refurbished. The Kerobokan prison, about 10 km (six miles) from the main tourist beaches in the Kuta area, often holds foreigners facing drug-related charges. Representatives of Beasley could not immediately be reached for comment. In June, an Australian, a Bulgarian, an Indian and a Malaysian tunneled to freedom about 12 meters (13 yards) under Kerobokan prison s walls. The Indian and the Bulgarian were caught soon after in neighboring East Timor, but Australian Shaun Edward Davidson and Malaysian Tee Kok King remain at large. Davidson has taunted authorities by saying he was enjoying life in various parts of the world, in purported posts on Facebook.  Kerobokan has housed a number of well-known foreign drug convicts, including Australian Schappelle Corby, whose 12-1/2-year sentence for marijuana smuggling got huge media attention.\"\n",
        "\n",
        "#result = clf(text)\n",
        "#result\n",
        "\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"jy46604790/Fake-News-Bert-Detect\")\n",
        "\n",
        "# 1. Pass a model name or path\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"jy46604790/Fake-News-Bert-Detect\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1} #LABEL_0: Fake news // LABEL_1: Real news\n",
        ")\n",
        "\n",
        "# 2. Pass an instantiated model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"jy46604790/Fake-News-Bert-Detect\")\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"jy46604790/Fake-News-Bert-Detect\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1} #LABEL_0: Fake news // LABEL_1: Real news\n",
        ")\n",
        "\n",
        "# 3. Pass an instantiated pipeline\n",
        "pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"jy46604790/Fake-News-Bert-Detect\"))\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1}, #LABEL_0: Fake news // LABEL_1: Real news\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "print(\"___________\")\n",
        "print(\"jy46604790\")\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(\"___________\")\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY-2wcfx_Uej"
      },
      "source": [
        "**4) MODEL: winterForestStump/Roberta-fake-news-detector (pre-trained on ISOT and EU news)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfCRRqEhATBV"
      },
      "outputs": [],
      "source": [
        "MODEL = \"winterForestStump/Roberta-fake-news-detector\"\n",
        "\n",
        "#clf = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL)\n",
        "\n",
        "#text = \"From the very beginning, the EU has been extremely non-transparent. The deployment of the European Union presence in Armenia was carried out forcefully, under serious pressure from Brussels\"\n",
        "\n",
        "#result = clf(text)\n",
        "#result\n",
        "\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\")\n",
        "\n",
        "# 1. Pass a model name or path\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        ")\n",
        "\n",
        "# 2. Pass an instantiated model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\")\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        ")\n",
        "\n",
        "# 3. Pass an instantiated pipeline\n",
        "pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\"))\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    label_mapping={\"FAKE\": 0, \"TRUE\": 1},\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "print(\"___________\")\n",
        "print(\"winterForestStump\")\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(\"___________\")\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muQpoK2EZsSc"
      },
      "source": [
        "**-) Run EU model over files with different seeds (42, 48, and 54)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OWha5XWaVz0E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "from evaluate import evaluator\n",
        "import evaluate\n",
        "from transformers import AutoModelForSequenceClassification, pipeline\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "seed_count = 42\n",
        "files_dir = \"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS\"\n",
        "eval_data = \"\"\n",
        "file_name = \"\"\n",
        "\n",
        "while seed_count <= 54:\n",
        "\n",
        "  for file_name in sorted(os.listdir(files_dir)):\n",
        "    f = os.path.join(files_dir, file_name)\n",
        "    if os.path.isfile(f):\n",
        "      #print(file_name)\n",
        "      eval_data = load_dataset(\"csv\", header=0, data_files=\"/content/drive/MyDrive/DATASETS/FINAL_DATASETS/EU_FINAL_DATASETS/\"+file_name, token=True, split=\"train\").shuffle(seed=seed_count).select(range(500))\n",
        "\n",
        "      MODEL = \"winterForestStump/Roberta-fake-news-detector\"\n",
        "      task_evaluator = evaluator(\"text-classification\")\n",
        "      tokenizer = AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\")\n",
        "\n",
        "      # 1. Pass a model name or path\n",
        "      eval_results = task_evaluator.compute(\n",
        "        model_or_pipeline=MODEL,\n",
        "        tokenizer=AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\"),\n",
        "        data=eval_data,\n",
        "        label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        "      )\n",
        "\n",
        "      # 2. Pass an instantiated model\n",
        "      model = AutoModelForSequenceClassification.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\")\n",
        "\n",
        "      eval_results = task_evaluator.compute(\n",
        "        model_or_pipeline=model,\n",
        "        tokenizer=AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\"),\n",
        "        data=eval_data,\n",
        "        label_mapping={\"FAKE\": 0, \"TRUE\": 1}\n",
        "      )\n",
        "\n",
        "      # 3. Pass an instantiated pipeline\n",
        "      pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"winterForestStump/Roberta-fake-news-detector\"))\n",
        "\n",
        "      eval_results = task_evaluator.compute(\n",
        "        model_or_pipeline=pipe,\n",
        "        data=eval_data,\n",
        "        metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "        label_mapping={\"FAKE\": 0, \"TRUE\": 1},\n",
        "        strategy=\"bootstrap\",\n",
        "        n_resamples=200\n",
        "      )\n",
        "      print(\"___________\")\n",
        "      print(\"winterForestStump\")\n",
        "      print(\"EVALUATION RESULTS (\" + \"FILE: \" + file_name + \"; SEED:\" + str(seed_count) + \"):\")\n",
        "      print(\"___________\")\n",
        "      print(eval_results)\n",
        "  seed_count += 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJClkz0KATKc"
      },
      "source": [
        "**5) MODEL: XSY/albert-base-v2-fakenews-discriminator (pre-trained on: ISOT)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsDf9KyaATac"
      },
      "outputs": [],
      "source": [
        "MODEL = \"XSY/albert-base-v2-fakenews-discriminator\"\n",
        "\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-fakenews-discriminator\")\n",
        "\n",
        "# 1. Pass a model name or path\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-fakenews-discriminator\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1} #label_0 : Fake news // label_1 : Real news\n",
        ")\n",
        "\n",
        "# 2. Pass an instantiated model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"XSY/albert-base-v2-fakenews-discriminator\")\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-fakenews-discriminator\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1} #label_0 : Fake news // label_1 : Real news\n",
        ")\n",
        "\n",
        "# 3. Pass an instantiated pipeline\n",
        "pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"XSY/albert-base-v2-fakenews-discriminator\"))\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    label_mapping={\"LABEL_0\": 0, \"LABEL_1\": 1}, #label_0 : Fake news // label_1 : Real news\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "print(\"___________\")\n",
        "print(\"XSY\")\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(\"___________\")\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-z0SzGnTPJF"
      },
      "source": [
        "**6) MODEL: Denyol/FakeNews-deberta-base (pre-trained on: COVID-19 fake news)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3k8zdmPThz0"
      },
      "outputs": [],
      "source": [
        "MODEL = \"Denyol/FakeNews-deberta-base\"\n",
        "\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Denyol/FakeNews-deberta-base\")\n",
        "\n",
        "# 1. Pass a model name or path\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"Denyol/FakeNews-deberta-base\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"REAL\": 1} #0: FAKE, 1: TRUE\n",
        ")\n",
        "\n",
        "# 2. Pass an instantiated model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Denyol/FakeNews-deberta-base\")\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"Denyol/FakeNews-deberta-base\"),\n",
        "    data=eval_data,\n",
        "    label_mapping={\"FAKE\": 0, \"REAL\": 1} #0: FAKE, 1: TRUE\n",
        ")\n",
        "\n",
        "# 3. Pass an instantiated pipeline\n",
        "pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"Denyol/FakeNews-deberta-base\"))\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    label_mapping={\"FAKE\": 0, \"REAL\": 1}, #0: FAKE, 1: TRUE\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "print(\"___________\")\n",
        "print(\"Denyol\")\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(\"___________\")\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRQl30ecTiC9"
      },
      "source": [
        "**7) MODEL: AlexanderHolmes0/fake-news-detector-long (pre-trained on: ISOT)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kNoq5Xvw9zH"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "#from evaluate import evaluator\n",
        "#import evaluate\n",
        "#from transformers import AutoModelForSequenceClassification, pipeline\n",
        "from datasets import Dataset\n",
        "#from transformers import AutoTokenizer\n",
        "\n",
        "print(\"Before label change:\", eval_data)\n",
        "df = pd.DataFrame(eval_data)\n",
        "df = df[[\"text\", \"label\"]]\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True).head(100)  #limit by head or sample size of data sample\n",
        "print(df)\n",
        "\n",
        "#only for this model (1=FALSE, 0=TRUE) - change label accordingly before evaluation (usually boolean true = binary 1 and boolean false = binary 0)\n",
        "def map_labels(eval_data):\n",
        "    eval_data[\"label\"] = not eval_data[\"label\"]\n",
        "    return eval_data\n",
        "\n",
        "result = eval_data.map(map_labels)\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(\"After label change:\", result)\n",
        "df = pd.DataFrame(result)\n",
        "df = df[[\"text\", \"label\"]]\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True).head(100)  #limit by head or sample size of data sample\n",
        "print(df)\n",
        "\n",
        "eval_data = result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1rFFKGpTiM0"
      },
      "outputs": [],
      "source": [
        "MODEL = \"AlexanderHolmes0/fake-news-detector-long\"\n",
        "\n",
        "task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"AlexanderHolmes0/fake-news-detector-long\")\n",
        "\n",
        "# 1. Pass a model name or path\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=MODEL,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"AlexanderHolmes0/fake-news-detector-long\"),\n",
        "    data=eval_data,\n",
        "    #label_mapping={\"true\": 1, \"fake\": 0} #1: true, 0: fake in evaluation data\n",
        "    label_mapping={\"true\": 0, \"fake\": 1}\n",
        ")\n",
        "\n",
        "# 2. Pass an instantiated model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"AlexanderHolmes0/fake-news-detector-long\")\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=model,\n",
        "    tokenizer=AutoTokenizer.from_pretrained(\"AlexanderHolmes0/fake-news-detector-long\"),\n",
        "    data=eval_data,\n",
        "    #label_mapping={\"true\": 1, \"fake\": 0} #1: true, 0: fake in evaluation data\n",
        "    label_mapping={\"true\": 0, \"fake\": 1}\n",
        ")\n",
        "\n",
        "# 3. Pass an instantiated pipeline\n",
        "pipe = pipeline(\"text-classification\", model=MODEL, tokenizer=AutoTokenizer.from_pretrained(\"AlexanderHolmes0/fake-news-detector-long\"))\n",
        "\n",
        "eval_results = task_evaluator.compute(\n",
        "    model_or_pipeline=pipe,\n",
        "    data=eval_data,\n",
        "    metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
        "    #label_mapping={\"true\": 1, \"fake\": 0} #1: true, 0: fake in evaluation data\n",
        "    label_mapping={\"true\": 0, \"fake\": 1},\n",
        "    strategy=\"bootstrap\",\n",
        "    n_resamples=200\n",
        ")\n",
        "print(\"___________\")\n",
        "print(\"AlexanderHolmes0\")\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(\"___________\")\n",
        "print(eval_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNyRMVLGhMy2uFx6eenOqVC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}